{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import sklearn\n",
    "from sklearn.naive_bayes  import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from feature_builder import process_dataset, _add_text_embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_dataset.loc[:,'target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero pruebo con tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "v = TfidfVectorizer()\n",
    "x_tfidf = v.fit_transform(train_dataset['text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_tfidf, x_test_tfidf, y_train_tfidf, y_test_tfidf = train_test_split(x_tfidf, y, test_size = .33, random_state = 17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "logisticRegr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logisticRegr.fit(x_train_tfidf, y_train_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_tfidf = logisticRegr.predict(x_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7362869198312237"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test_tfidf, y_pred_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora voy a probar con el process_dataset de feature_builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of words covered in the embeddings = 0.6336399642263958\n"
     ]
    }
   ],
   "source": [
    "x_processed = process_dataset(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>invalid_location_character_count</th>\n",
       "      <th>location_is_place</th>\n",
       "      <th>mean_encode</th>\n",
       "      <th>keyword_length</th>\n",
       "      <th>text_length</th>\n",
       "      <th>location_length</th>\n",
       "      <th>stop_word_count</th>\n",
       "      <th>punctuation_count</th>\n",
       "      <th>hashtag_count</th>\n",
       "      <th>mention_count</th>\n",
       "      <th>...</th>\n",
       "      <th>text_embedding_290</th>\n",
       "      <th>text_embedding_291</th>\n",
       "      <th>text_embedding_292</th>\n",
       "      <th>text_embedding_293</th>\n",
       "      <th>text_embedding_294</th>\n",
       "      <th>text_embedding_295</th>\n",
       "      <th>text_embedding_296</th>\n",
       "      <th>text_embedding_297</th>\n",
       "      <th>text_embedding_298</th>\n",
       "      <th>text_embedding_299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.634667</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.055542</td>\n",
       "      <td>0.115112</td>\n",
       "      <td>-0.114197</td>\n",
       "      <td>-0.073990</td>\n",
       "      <td>-0.028381</td>\n",
       "      <td>0.010828</td>\n",
       "      <td>-0.061638</td>\n",
       "      <td>-0.080215</td>\n",
       "      <td>-0.020348</td>\n",
       "      <td>0.119019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.634667</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.059473</td>\n",
       "      <td>-0.018774</td>\n",
       "      <td>-0.040625</td>\n",
       "      <td>0.167126</td>\n",
       "      <td>0.067529</td>\n",
       "      <td>0.010791</td>\n",
       "      <td>-0.139258</td>\n",
       "      <td>-0.042334</td>\n",
       "      <td>0.070020</td>\n",
       "      <td>0.054913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.634667</td>\n",
       "      <td>0</td>\n",
       "      <td>133</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.068675</td>\n",
       "      <td>-0.000366</td>\n",
       "      <td>-0.106979</td>\n",
       "      <td>-0.019196</td>\n",
       "      <td>0.020692</td>\n",
       "      <td>0.031937</td>\n",
       "      <td>-0.069041</td>\n",
       "      <td>0.020345</td>\n",
       "      <td>0.021281</td>\n",
       "      <td>-0.016398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.634667</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.208557</td>\n",
       "      <td>-0.069417</td>\n",
       "      <td>-0.071248</td>\n",
       "      <td>0.039714</td>\n",
       "      <td>0.195394</td>\n",
       "      <td>0.079915</td>\n",
       "      <td>-0.236613</td>\n",
       "      <td>0.025553</td>\n",
       "      <td>-0.026367</td>\n",
       "      <td>-0.033366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.634667</td>\n",
       "      <td>0</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.080957</td>\n",
       "      <td>-0.128174</td>\n",
       "      <td>-0.070508</td>\n",
       "      <td>0.061353</td>\n",
       "      <td>0.019550</td>\n",
       "      <td>-0.023505</td>\n",
       "      <td>0.016354</td>\n",
       "      <td>-0.053082</td>\n",
       "      <td>0.030786</td>\n",
       "      <td>0.031708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7608</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.634667</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.127472</td>\n",
       "      <td>0.016769</td>\n",
       "      <td>-0.119431</td>\n",
       "      <td>-0.029610</td>\n",
       "      <td>0.010361</td>\n",
       "      <td>-0.045746</td>\n",
       "      <td>-0.038895</td>\n",
       "      <td>-0.090240</td>\n",
       "      <td>-0.001657</td>\n",
       "      <td>-0.127274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7609</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.634667</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004173</td>\n",
       "      <td>0.020516</td>\n",
       "      <td>-0.027425</td>\n",
       "      <td>0.006314</td>\n",
       "      <td>0.001776</td>\n",
       "      <td>-0.016901</td>\n",
       "      <td>-0.112602</td>\n",
       "      <td>-0.011907</td>\n",
       "      <td>0.046770</td>\n",
       "      <td>-0.023856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7610</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.634667</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.174235</td>\n",
       "      <td>0.122884</td>\n",
       "      <td>-0.046224</td>\n",
       "      <td>0.060221</td>\n",
       "      <td>-0.155924</td>\n",
       "      <td>-0.039388</td>\n",
       "      <td>-0.201172</td>\n",
       "      <td>0.010946</td>\n",
       "      <td>0.118978</td>\n",
       "      <td>0.344401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7611</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.634667</td>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.090700</td>\n",
       "      <td>0.071742</td>\n",
       "      <td>-0.048296</td>\n",
       "      <td>0.061262</td>\n",
       "      <td>-0.116019</td>\n",
       "      <td>-0.001737</td>\n",
       "      <td>-0.046749</td>\n",
       "      <td>-0.062116</td>\n",
       "      <td>0.018721</td>\n",
       "      <td>-0.048802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7612</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.634667</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.058301</td>\n",
       "      <td>-0.035309</td>\n",
       "      <td>-0.062359</td>\n",
       "      <td>0.111095</td>\n",
       "      <td>0.096863</td>\n",
       "      <td>-0.088300</td>\n",
       "      <td>-0.172668</td>\n",
       "      <td>0.018494</td>\n",
       "      <td>0.059473</td>\n",
       "      <td>-0.025171</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7613 rows × 331 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      invalid_location_character_count  location_is_place  mean_encode  \\\n",
       "0                                    0                  0     0.634667   \n",
       "1                                    0                  0     0.634667   \n",
       "2                                    0                  0     0.634667   \n",
       "3                                    0                  0     0.634667   \n",
       "4                                    0                  0     0.634667   \n",
       "...                                ...                ...          ...   \n",
       "7608                                 0                  0     0.634667   \n",
       "7609                                 0                  0     0.634667   \n",
       "7610                                 0                  0     0.634667   \n",
       "7611                                 0                  0     0.634667   \n",
       "7612                                 0                  0     0.634667   \n",
       "\n",
       "      keyword_length  text_length  location_length  stop_word_count  \\\n",
       "0                  0           69                0                6   \n",
       "1                  0           38                0                0   \n",
       "2                  0          133                0               11   \n",
       "3                  0           65                0                1   \n",
       "4                  0           88                0                7   \n",
       "...              ...          ...              ...              ...   \n",
       "7608               0           83                0                2   \n",
       "7609               0          125                0                9   \n",
       "7610               0           65                0                2   \n",
       "7611               0          137                0                5   \n",
       "7612               0           94                0                3   \n",
       "\n",
       "      punctuation_count  hashtag_count  mention_count  ...  \\\n",
       "0                     1              1              0  ...   \n",
       "1                     1              0              0  ...   \n",
       "2                     3              0              0  ...   \n",
       "3                     2              1              0  ...   \n",
       "4                     2              2              0  ...   \n",
       "...                 ...            ...            ...  ...   \n",
       "7608                  5              0              0  ...   \n",
       "7609                  5              0              2  ...   \n",
       "7610                 11              0              0  ...   \n",
       "7611                  5              0              0  ...   \n",
       "7612                  7              0              0  ...   \n",
       "\n",
       "      text_embedding_290  text_embedding_291  text_embedding_292  \\\n",
       "0              -0.055542            0.115112           -0.114197   \n",
       "1              -0.059473           -0.018774           -0.040625   \n",
       "2              -0.068675           -0.000366           -0.106979   \n",
       "3               0.208557           -0.069417           -0.071248   \n",
       "4               0.080957           -0.128174           -0.070508   \n",
       "...                  ...                 ...                 ...   \n",
       "7608           -0.127472            0.016769           -0.119431   \n",
       "7609            0.004173            0.020516           -0.027425   \n",
       "7610            0.174235            0.122884           -0.046224   \n",
       "7611            0.090700            0.071742           -0.048296   \n",
       "7612            0.058301           -0.035309           -0.062359   \n",
       "\n",
       "      text_embedding_293  text_embedding_294  text_embedding_295  \\\n",
       "0              -0.073990           -0.028381            0.010828   \n",
       "1               0.167126            0.067529            0.010791   \n",
       "2              -0.019196            0.020692            0.031937   \n",
       "3               0.039714            0.195394            0.079915   \n",
       "4               0.061353            0.019550           -0.023505   \n",
       "...                  ...                 ...                 ...   \n",
       "7608           -0.029610            0.010361           -0.045746   \n",
       "7609            0.006314            0.001776           -0.016901   \n",
       "7610            0.060221           -0.155924           -0.039388   \n",
       "7611            0.061262           -0.116019           -0.001737   \n",
       "7612            0.111095            0.096863           -0.088300   \n",
       "\n",
       "      text_embedding_296  text_embedding_297  text_embedding_298  \\\n",
       "0              -0.061638           -0.080215           -0.020348   \n",
       "1              -0.139258           -0.042334            0.070020   \n",
       "2              -0.069041            0.020345            0.021281   \n",
       "3              -0.236613            0.025553           -0.026367   \n",
       "4               0.016354           -0.053082            0.030786   \n",
       "...                  ...                 ...                 ...   \n",
       "7608           -0.038895           -0.090240           -0.001657   \n",
       "7609           -0.112602           -0.011907            0.046770   \n",
       "7610           -0.201172            0.010946            0.118978   \n",
       "7611           -0.046749           -0.062116            0.018721   \n",
       "7612           -0.172668            0.018494            0.059473   \n",
       "\n",
       "      text_embedding_299  \n",
       "0               0.119019  \n",
       "1               0.054913  \n",
       "2              -0.016398  \n",
       "3              -0.033366  \n",
       "4               0.031708  \n",
       "...                  ...  \n",
       "7608           -0.127274  \n",
       "7609           -0.023856  \n",
       "7610            0.344401  \n",
       "7611           -0.048802  \n",
       "7612           -0.025171  \n",
       "\n",
       "[7613 rows x 331 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_processed, x_test_processed, y_train_processed, y_test_processed = train_test_split(x_processed, y, test_size = .33, random_state = 17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andres/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logisticRegr.fit(x_train_processed, y_train_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_processed = logisticRegr.predict(x_test_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7398568019093079"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test_processed, y_pred_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of words covered in the embeddings = 0.6336399642263958\n"
     ]
    }
   ],
   "source": [
    "x_embedd = train_dataset.copy()\n",
    "_add_text_embeddings(x_embedd)\n",
    "x_embedd.drop(['text', 'location', 'keyword', 'id', 'target'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Me quede solo con los embeddings ya que el resto deteriora el algoritmo por alguna razón."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_embedd, x_test_embedd, y_train_embedd, y_test_embedd = train_test_split(x_embedd, y, test_size = .33, random_state = 17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logisticRegr.fit(x_train_embedd, y_train_embedd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_embedd = logisticRegr.predict(x_test_embedd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.751434034416826"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test_embedd, y_pred_embedd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
