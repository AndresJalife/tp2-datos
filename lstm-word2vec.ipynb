{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jorge/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/jorge/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to /home/jorge/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.preprocessing import sequence\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from gensim.models import KeyedVectors\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, Flatten, MaxPooling1D, Embedding, GlobalMaxPooling1D, Dropout, LSTM,Input,Activation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import nltk\n",
    "from sklearn.metrics import f1_score\n",
    "import feature_builder\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "embeddings = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spliteo para obtener vectores de train y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "Y = train_df['target'].values\n",
    "#train,test = train_test_split(train_df,test_size=0.33,random_state = 17)\n",
    "#train.reset_index(inplace=True,drop=True)\n",
    "#test.reset_index(inplace=True,drop=True)\n",
    "#y_train = train['target'].values\n",
    "#y_test = test['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_cnn(df):\n",
    "    processed = feature_builder.process_dataset(df)\n",
    "    return (processed, processed.to_numpy().reshape(processed.shape[0], 1, processed.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of words covered in the embeddings = 0.6336399642263958\n"
     ]
    }
   ],
   "source": [
    "processed, X_processed = prepare_for_cnn(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>invalid_location_character_count</th>\n",
       "      <th>location_is_place</th>\n",
       "      <th>mean_encode</th>\n",
       "      <th>keyword_length</th>\n",
       "      <th>text_length</th>\n",
       "      <th>location_length</th>\n",
       "      <th>stop_word_count</th>\n",
       "      <th>punctuation_count</th>\n",
       "      <th>hashtag_count</th>\n",
       "      <th>mention_count</th>\n",
       "      <th>...</th>\n",
       "      <th>text_embedding_290</th>\n",
       "      <th>text_embedding_291</th>\n",
       "      <th>text_embedding_292</th>\n",
       "      <th>text_embedding_293</th>\n",
       "      <th>text_embedding_294</th>\n",
       "      <th>text_embedding_295</th>\n",
       "      <th>text_embedding_296</th>\n",
       "      <th>text_embedding_297</th>\n",
       "      <th>text_embedding_298</th>\n",
       "      <th>text_embedding_299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.585906</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.055542</td>\n",
       "      <td>0.115112</td>\n",
       "      <td>-0.114197</td>\n",
       "      <td>-0.073990</td>\n",
       "      <td>-0.028381</td>\n",
       "      <td>0.010828</td>\n",
       "      <td>-0.061638</td>\n",
       "      <td>-0.080215</td>\n",
       "      <td>-0.020348</td>\n",
       "      <td>0.119019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.585906</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.059473</td>\n",
       "      <td>-0.018774</td>\n",
       "      <td>-0.040625</td>\n",
       "      <td>0.167126</td>\n",
       "      <td>0.067529</td>\n",
       "      <td>0.010791</td>\n",
       "      <td>-0.139258</td>\n",
       "      <td>-0.042334</td>\n",
       "      <td>0.070020</td>\n",
       "      <td>0.054913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.585906</td>\n",
       "      <td>0</td>\n",
       "      <td>133</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.068675</td>\n",
       "      <td>-0.000366</td>\n",
       "      <td>-0.106979</td>\n",
       "      <td>-0.019196</td>\n",
       "      <td>0.020692</td>\n",
       "      <td>0.031937</td>\n",
       "      <td>-0.069041</td>\n",
       "      <td>0.020345</td>\n",
       "      <td>0.021281</td>\n",
       "      <td>-0.016398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.585906</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.208557</td>\n",
       "      <td>-0.069417</td>\n",
       "      <td>-0.071248</td>\n",
       "      <td>0.039714</td>\n",
       "      <td>0.195394</td>\n",
       "      <td>0.079915</td>\n",
       "      <td>-0.236613</td>\n",
       "      <td>0.025553</td>\n",
       "      <td>-0.026367</td>\n",
       "      <td>-0.033366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.585906</td>\n",
       "      <td>0</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.080957</td>\n",
       "      <td>-0.128174</td>\n",
       "      <td>-0.070508</td>\n",
       "      <td>0.061353</td>\n",
       "      <td>0.019550</td>\n",
       "      <td>-0.023505</td>\n",
       "      <td>0.016354</td>\n",
       "      <td>-0.053082</td>\n",
       "      <td>0.030786</td>\n",
       "      <td>0.031708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7608</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.585906</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.127472</td>\n",
       "      <td>0.016769</td>\n",
       "      <td>-0.119431</td>\n",
       "      <td>-0.029610</td>\n",
       "      <td>0.010361</td>\n",
       "      <td>-0.045746</td>\n",
       "      <td>-0.038895</td>\n",
       "      <td>-0.090240</td>\n",
       "      <td>-0.001657</td>\n",
       "      <td>-0.127274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7609</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.585906</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004173</td>\n",
       "      <td>0.020516</td>\n",
       "      <td>-0.027425</td>\n",
       "      <td>0.006314</td>\n",
       "      <td>0.001776</td>\n",
       "      <td>-0.016901</td>\n",
       "      <td>-0.112602</td>\n",
       "      <td>-0.011907</td>\n",
       "      <td>0.046770</td>\n",
       "      <td>-0.023856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7610</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.585906</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.174235</td>\n",
       "      <td>0.122884</td>\n",
       "      <td>-0.046224</td>\n",
       "      <td>0.060221</td>\n",
       "      <td>-0.155924</td>\n",
       "      <td>-0.039388</td>\n",
       "      <td>-0.201172</td>\n",
       "      <td>0.010946</td>\n",
       "      <td>0.118978</td>\n",
       "      <td>0.344401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7611</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.585906</td>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.090700</td>\n",
       "      <td>0.071742</td>\n",
       "      <td>-0.048296</td>\n",
       "      <td>0.061262</td>\n",
       "      <td>-0.116019</td>\n",
       "      <td>-0.001737</td>\n",
       "      <td>-0.046749</td>\n",
       "      <td>-0.062116</td>\n",
       "      <td>0.018721</td>\n",
       "      <td>-0.048802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7612</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.585906</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.058301</td>\n",
       "      <td>-0.035309</td>\n",
       "      <td>-0.062359</td>\n",
       "      <td>0.111095</td>\n",
       "      <td>0.096863</td>\n",
       "      <td>-0.088300</td>\n",
       "      <td>-0.172668</td>\n",
       "      <td>0.018494</td>\n",
       "      <td>0.059473</td>\n",
       "      <td>-0.025171</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7613 rows × 331 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      invalid_location_character_count  location_is_place  mean_encode  \\\n",
       "0                                    0                  0     0.585906   \n",
       "1                                    0                  0     0.585906   \n",
       "2                                    0                  0     0.585906   \n",
       "3                                    0                  0     0.585906   \n",
       "4                                    0                  0     0.585906   \n",
       "...                                ...                ...          ...   \n",
       "7608                                 0                  0     0.585906   \n",
       "7609                                 0                  0     0.585906   \n",
       "7610                                 0                  0     0.585906   \n",
       "7611                                 0                  0     0.585906   \n",
       "7612                                 0                  0     0.585906   \n",
       "\n",
       "      keyword_length  text_length  location_length  stop_word_count  \\\n",
       "0                  0           69                0                6   \n",
       "1                  0           38                0                0   \n",
       "2                  0          133                0               11   \n",
       "3                  0           65                0                1   \n",
       "4                  0           88                0                7   \n",
       "...              ...          ...              ...              ...   \n",
       "7608               0           83                0                2   \n",
       "7609               0          125                0                9   \n",
       "7610               0           65                0                2   \n",
       "7611               0          137                0                5   \n",
       "7612               0           94                0                3   \n",
       "\n",
       "      punctuation_count  hashtag_count  mention_count  ...  \\\n",
       "0                     1              1              0  ...   \n",
       "1                     1              0              0  ...   \n",
       "2                     3              0              0  ...   \n",
       "3                     2              1              0  ...   \n",
       "4                     2              2              0  ...   \n",
       "...                 ...            ...            ...  ...   \n",
       "7608                  5              0              0  ...   \n",
       "7609                  5              0              2  ...   \n",
       "7610                 11              0              0  ...   \n",
       "7611                  5              0              0  ...   \n",
       "7612                  7              0              0  ...   \n",
       "\n",
       "      text_embedding_290  text_embedding_291  text_embedding_292  \\\n",
       "0              -0.055542            0.115112           -0.114197   \n",
       "1              -0.059473           -0.018774           -0.040625   \n",
       "2              -0.068675           -0.000366           -0.106979   \n",
       "3               0.208557           -0.069417           -0.071248   \n",
       "4               0.080957           -0.128174           -0.070508   \n",
       "...                  ...                 ...                 ...   \n",
       "7608           -0.127472            0.016769           -0.119431   \n",
       "7609            0.004173            0.020516           -0.027425   \n",
       "7610            0.174235            0.122884           -0.046224   \n",
       "7611            0.090700            0.071742           -0.048296   \n",
       "7612            0.058301           -0.035309           -0.062359   \n",
       "\n",
       "      text_embedding_293  text_embedding_294  text_embedding_295  \\\n",
       "0              -0.073990           -0.028381            0.010828   \n",
       "1               0.167126            0.067529            0.010791   \n",
       "2              -0.019196            0.020692            0.031937   \n",
       "3               0.039714            0.195394            0.079915   \n",
       "4               0.061353            0.019550           -0.023505   \n",
       "...                  ...                 ...                 ...   \n",
       "7608           -0.029610            0.010361           -0.045746   \n",
       "7609            0.006314            0.001776           -0.016901   \n",
       "7610            0.060221           -0.155924           -0.039388   \n",
       "7611            0.061262           -0.116019           -0.001737   \n",
       "7612            0.111095            0.096863           -0.088300   \n",
       "\n",
       "      text_embedding_296  text_embedding_297  text_embedding_298  \\\n",
       "0              -0.061638           -0.080215           -0.020348   \n",
       "1              -0.139258           -0.042334            0.070020   \n",
       "2              -0.069041            0.020345            0.021281   \n",
       "3              -0.236613            0.025553           -0.026367   \n",
       "4               0.016354           -0.053082            0.030786   \n",
       "...                  ...                 ...                 ...   \n",
       "7608           -0.038895           -0.090240           -0.001657   \n",
       "7609           -0.112602           -0.011907            0.046770   \n",
       "7610           -0.201172            0.010946            0.118978   \n",
       "7611           -0.046749           -0.062116            0.018721   \n",
       "7612           -0.172668            0.018494            0.059473   \n",
       "\n",
       "      text_embedding_299  \n",
       "0               0.119019  \n",
       "1               0.054913  \n",
       "2              -0.016398  \n",
       "3              -0.033366  \n",
       "4               0.031708  \n",
       "...                  ...  \n",
       "7608           -0.127274  \n",
       "7609           -0.023856  \n",
       "7610            0.344401  \n",
       "7611           -0.048802  \n",
       "7612           -0.025171  \n",
       "\n",
       "[7613 rows x 331 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_processed,Y,test_size = 0.33,random_state = 17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RNN():\n",
    "    model = Sequential([\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64),input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional_1 (Bidirection (None, 128)               202752    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 211,073\n",
      "Trainable params: 211,073\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = RNN()\n",
    "model.summary()\n",
    "model.compile(loss=keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer=keras.optimizers.Adam(1e-4),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "128/128 [==============================] - 1s 9ms/step - loss: 0.3188 - accuracy: 0.8578 - val_loss: 0.5273 - val_accuracy: 0.7775\n",
      "Epoch 2/50\n",
      "128/128 [==============================] - 1s 12ms/step - loss: 0.3171 - accuracy: 0.8588 - val_loss: 0.5233 - val_accuracy: 0.7775\n",
      "Epoch 3/50\n",
      "128/128 [==============================] - 1s 9ms/step - loss: 0.3160 - accuracy: 0.8620 - val_loss: 0.5363 - val_accuracy: 0.7725\n",
      "Epoch 4/50\n",
      "105/128 [=======================>......] - ETA: 0s - loss: 0.3150 - accuracy: 0.8604"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=50, shuffle=True, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-15-f10058649000>:1: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8042180660565061"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7368983957219252"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
